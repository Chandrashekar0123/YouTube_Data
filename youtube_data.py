# -*- coding: utf-8 -*-
"""YouTube_data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gd0S6QEaJmaFd0ANeWDhDZoBoS0OdlOL

##Accesing YouTube data

#Billboard Hot 100 playlist

The Billboard Hot 100 playlist features the top 100 songs in the U.S., updated weekly. It includes the biggest hits across various genres, reflecting the current chart rankings based on streaming, radio play, and sales. The playlist is a great way to discover the latest popular music and chart-toppers.

##Install Google API client, pandas, and openpyxl libraries
"""

!pip install google-api-python-client pandas openpyxl

"""##Import all neccesary libraries"""

from googleapiclient.discovery import build
import pandas as pd
import re

"""## Your YouTube API Key. Make sure to replace this with your own key from the Google Cloud Console."""

# Replace with your API Key
API_KEY = 'AIzaSyBP-MmUNm-FgbMXWclmLSUdrTQHbpPI8Es'

"""# Create a YouTube API client"""

youtube = build("youtube", "v3", developerKey=API_KEY)

"""# Replace with your actual Playlist ID (not URL)"""

playlist_id = "PLDIoUOhQQPlWc-Kd6TCjTRIl0Z6fSQV0X"  # Example: PLbVdsQ0VoFz_abcdef1234567890

"""# Function to convert ISO 8601 duration to minutes"""

def convert_duration_to_minutes(duration):
    pattern = re.compile(r"PT(\d+M)?")
    match = pattern.match(duration)

    if match:
        minutes = match.group(1)
        if minutes:
            return int(minutes[:-1])  # Remove 'M' and convert to integer
    return 0  # Return 0 if duration is not in the expected format

"""# Create a list to store the video data"""

video_data = []

# Pagination handling
next_page_token = None

"""## maxResults specifies the number of videos to fetch per request (up to 50 max).

## Request a batch of video details from the playlist using the current page token.
"""

while True:
    # Request video details from the playlist
    request = youtube.playlistItems().list(
        part="snippet",
        playlistId=playlist_id,
        maxResults=50,  # Adjust the number of videos to fetch (up to 50 per request)
        pageToken=next_page_token
    )

""" # Execute the API request and fetch the response containing video details for the current page."""

response = request.execute()

"""# Iterate over each video item in the response and extract relevant details."""

for item in response["items"]:
        video_title = item["snippet"]["title"]  # Extract the video's title.
        video_description = item["snippet"]["description"]  # Extract the video's description.
        video_published_at = item["snippet"]["publishedAt"]  # Extract the video's published date and time.
        video_url = f'https://www.youtube.com/watch?v={item["snippet"]["resourceId"]["videoId"]}'  # Construct the video's URL.
        video_id = item["snippet"]["resourceId"]["videoId"]  # Extract the unique video ID.

"""  # Fetch additional details about the video such as statistics (views, likes, etc.),
   # content details (duration, etc.), and snippet (additional metadata).
"""

# Fetch additional details (view count, like count, dislike count, comment count, etc.)
        video_details_request = youtube.videos().list(
            part="statistics,contentDetails,snippet",
            id=video_id
        )

"""  # Execute the request to retrieve the video details from the YouTube API."""

video_details_response = video_details_request.execute()

""" # Extract statistics and details for the video, such as view count, like count, etc.
       
"""

view_count = video_details_response["items"][0]["statistics"].get("viewCount", "N/A")
        like_count = video_details_response["items"][0]["statistics"].get("likeCount", "N/A")
        dislike_count = video_details_response["items"][0]["statistics"].get("dislikeCount", "N/A")  # Note: Dislikes are deprecated
        comment_count = video_details_response["items"][0]["statistics"].get("commentCount", "N/A")
        tags = video_details_response["items"][0]["snippet"].get("tags", [])
        duration = video_details_response["items"][0]["contentDetails"].get("duration", "PT0M")

""" # Convert duration to minutes"""

duration_in_minutes = convert_duration_to_minutes(duration)

""" # Append data to the list"""

video_data.append([video_title, video_description, video_published_at, video_url, view_count, like_count, dislike_count,
                           comment_count, tags, duration_in_minutes])

"""  # Check if there's another page of videos in the playlist"""

# Check if there's another page of videos
    next_page_token = response.get('nextPageToken')

    # Break the loop if no more pages
    if not next_page_token:
        break

"""# Convert the list to a DataFrame"""

df = pd.DataFrame(video_data, columns=["Title", "Description", "Published At", "Video URL", "View Count", "Like Count",
                                       "Dislike Count", "Comment Count", "Tags", "Duration (Minutes)"])

"""# Save the data to an Excel file"""

df.to_excel("youtube_video_data_with_likes_dislikes.xlsx", index=False)

print("Data has been saved to youtube_video_data_with_likes_dislikes.xlsx")

"""# Loop through all pages of the playlist until there are no more pages"""

while "nextPageToken" in response:
    # Extract the token for the next page of results
    next_page_token = response["nextPageToken"]

    # Request the next page of video details from the playlist
    request = youtube.playlistItems().list(
        part="snippet",         # Specify the part of the video details to retrieve
        playlistId=playlist_id, # The ID of the playlist to fetch videos from
        maxResults=50,          # Maximum number of videos per request (YouTube API limit is 50)
        pageToken=next_page_token  # Use the token to fetch the next page
    )

    # Execute the API request to get the next set of videos
    response = request.execute()

    # Process the videos in the current page and append data to the video_data list

